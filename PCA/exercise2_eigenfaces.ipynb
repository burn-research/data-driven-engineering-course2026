{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6faa05",
   "metadata": {},
   "source": [
    "# 2 Session : POD\n",
    "\n",
    "## Intro and terminology\n",
    "\n",
    "POD and PCA are two closely related, dual approaches to dimensionality reduction. Although both rely on the singular value decomposition (SVD), their notations differ, which can be confusing at first. The conventions used in this course are summarised below:\n",
    "\n",
    "* D or X := dataset\n",
    "* L := matrix of eigenvalues\n",
    "* L* or $\\Sigma$ := matrix of singular values\n",
    "* K = $X^T X$ := covariance matrix between colomns\n",
    "* C = $X X^T$ := covariance matrix between rows\n",
    "\n",
    "### PCA\n",
    "\n",
    "* n := number of observations\n",
    "* m := number of features\n",
    "\n",
    "The aim is to reduce the dimensionality of $D_{n, m}$ with respect to the m features (from m to q):\n",
    "\n",
    "* $A_{m, m}$ := Matrix of right-eigenvectors (its elements are called *loadings*) s.t. $K = ALA^T$\n",
    "* $Z_{n, m}$ = $D_{n, m}A_{m,m}$ := Rotation of the dataset along the Principal Components (PCs) (its elements are called *scores*)\n",
    "* $Z_{n, q}$ := Low-dimensional projection (q < m)\n",
    "\n",
    "### POD\n",
    "\n",
    "* n := number of features (flipped with respect to PCA !)\n",
    "* m := number of observations\n",
    "\n",
    "The aim is to reduce the dimensionality of $D_{n, m}$ with respect to the n features (from n to q):\n",
    "\n",
    "* $\\Psi_{m, m}$ := Matrix of right-eigenvectors s.t. $K = \\Psi L\\Psi^T$\n",
    "* $\\Phi_{n, m}$ := Matrix of left-eigenvectors (its elements are called modes) s.t. $C = \\Phi L\\Phi^T$\n",
    "* $A^T_{m, m} = L^*\\Psi^T$ := Low-dimensional projection of the dataset (from n to m)\n",
    "* $A^T_{q, m}$ := Low-dimensional projection of the dataset (truncated, from n to q < m)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f511b",
   "metadata": {},
   "source": [
    "## Exercise 1: Face images\n",
    "\n",
    "The goal of the exercise is to perform POD on a dataset containing face images\n",
    "The dataset contains 400 64x64 images of human faces.\n",
    "How can POD help in reconstructing faces (in an optimal way)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0476ae",
   "metadata": {},
   "source": [
    "In the first cell we import the libraries that we are going to use and the face dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "face_images= fetch_olivetti_faces().images\n",
    "print(face_images.shape) #check the dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef04079a",
   "metadata": {},
   "source": [
    "We can also plot same faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbbf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the index of the face to show\n",
    "index = 0\n",
    "\n",
    "# select the image and reshape it to show it\n",
    "face = face_images[index,:]\n",
    "plt.title(f'Face number = {index}')\n",
    "plt.imshow(face, cmap='grey')\n",
    "plt.xticks(np.linspace(0, 63, 8))\n",
    "plt.yticks(np.linspace(0, 63, 8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f8075d",
   "metadata": {},
   "source": [
    " - For convenience, please define the number of images of faces as **Nfaces** and the total number of pixeles as **Npix** using the *.shape* method\n",
    "\n",
    " - To be able to apply POD, we need a matrix. Please reshape the tensor face_images as a matrix of size ($n_{features}, n_{observations}$) (it will be our \"X\") and call it **face_X**\n",
    "\n",
    "> Hint: Here, **Nfaces** is the number of observations (snapshots) and **Npix** is the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ff90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nfaces  = ...\n",
    "# Npix    = ... \n",
    "# print(f'Nfaces = {Nfaces}')\n",
    "# print(f'Npix   = {Npix}')\n",
    "\n",
    "# face_X = face_images.reshape(  ... \n",
    "# print(face_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622e44f",
   "metadata": {},
   "source": [
    "##  Implement POD\n",
    "Now, we write a function to **implement the POD algorithm**. Conventionally, the mean is removed from the dataset before applying POD. If this is not done, the mean will be the first PC.\n",
    "\n",
    " - Hint to define POD:\n",
    "     1. center the matrix X\n",
    "     2. compute the covariance matrix K = X0.T @ X0\n",
    "     3. compute the eigendecomposition using np.linalg.eig\n",
    "     4. sort the eigenvalues using np.sort and np.argsort\n",
    "     5. compute the POD modes Z = X0 @ Psi\n",
    "     6. normalize the POD modes phi[i] = z[i]/np.linalg.norm(z[i])\n",
    "   \n",
    "> Q: Why don't we scale the matrix X as before? Because all our features (pixels) represent the same thing, and they are already scaled between 0 and 1!\n",
    "> \n",
    "> Q: Why do we compute K instead of C? Think about the dimensions of K and C ...\n",
    "> \n",
    "> Q: Why can we compute the POD modes like that? Starting from what we know, we can see it like that:\n",
    "> \n",
    "> If $Z = X_0\\Psi$, $X_0 = Z\\Psi^T$, then $K = X^TX = \\Psi Z^TZ \\Psi^T = \\Psi L \\Psi^T$ &rarr; $L = Z^TZ = (L^*)^2$ (1)\n",
    ">\n",
    "> But since $X_0 = \\Phi L^* \\Psi^T$, $Z = X_0 \\Psi = \\Phi L^*$ (2)\n",
    ">\n",
    "> Finally, if you isolate $\\Phi$ using (1) and (2), you find that its columns are the normalised POD modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced340c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the POD function\n",
    "\n",
    "# def POD(X):\n",
    "#     X_mean = ...\n",
    "#     X_std = ...\n",
    "    \n",
    "#     X0 = ...\n",
    "\n",
    "#     K = ...\n",
    "\n",
    "#     l, Psi = ...\n",
    "\n",
    "#     Z = ...\n",
    "\n",
    "#     Phi = ...\n",
    "    \n",
    "#     return Psi, Phi, l\n",
    "\n",
    "# Uncomment when you have defined the function POD\n",
    "# Psi, Phi, l = POD(face_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed09a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when you have perfomed POD\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(4,4))\n",
    "# ax.scatter(np.linspace(1, Nfaces, Nfaces), l, s=5)\n",
    "# ax.set_title('POD eigenvalues')\n",
    "# plt.xlim([0, Nfaces])\n",
    "# plt.xlabel('PC number')\n",
    "# plt.ylabel('Eigenvalues')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339237db",
   "metadata": {},
   "source": [
    "##  Compute POD using the SVD \n",
    "Now, we can perform POD using directly the SVD and compute the explained variance as a function of the modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7dbe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the np.linalg.svd function\n",
    "\n",
    "face_X_mean = ...\n",
    "face_X0 = ...\n",
    "\n",
    "# SVD\n",
    "Phi, sigma, Psi_t = ...\n",
    "\n",
    "ex_var = ...\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(np.arange(Nfaces) + 1, ex_var, s=5, color='k', label='ex. var.')\n",
    "# plt.scatter(np.arange(Nfaces) + 1, np.cumsum(ex_var), s=5, color='r', label='cum. ex. var.')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a185b6c",
   "metadata": {},
   "source": [
    " ##### Show the first eigenfaces.\n",
    " \n",
    "- Plot the first n=5 eigenfaces.\n",
    "\n",
    "> Does it look likes ghosts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this lines to show the eigenfaces:\n",
    "# We can plot the first 5 modes \n",
    "\n",
    "# n = 5\n",
    "# fig, axs = plt.subplots(1, n, figsize=(3*n, 3))\n",
    "# for i, ax in enumerate(axs):\n",
    "#     im = Phi.T.reshape(face_images.shape)[i, :]\n",
    "#     ax.imshow(im, cmap='grey')\n",
    "#     ax.set_title('Mode ' + str(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f918a",
   "metadata": {},
   "source": [
    "##### Test POD as a reduced-order model (ROM)\n",
    "We can also check if we can use POD to achieve dimensionality reduction. This means that we can reconstructed the faces using few modes.\n",
    "\n",
    "- To do:\n",
    "    1. reconstruct the face number 10 using the first 10 modes, and compare it to the original\n",
    "    2. reconstruct the same face with 1,5, 10, 100, 200 and 400 modes. Compare the solution\n",
    "    \n",
    "    \n",
    "- hint: X_reconstructed = mean + Phi_q Aq.T \n",
    "- hint: Aq.T = Sigma_q @ Psi_q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25452f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the face number 10\n",
    "# index = 10\n",
    "# face_orig = face_X[:, index] # original face\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(face_orig.reshape(face_images.shape[1:]), cmap='grey')\n",
    "# plt.show()\n",
    "\n",
    "# Low-dimensional projection\n",
    "At = ...\n",
    "A = ...\n",
    "\n",
    "# Modes\n",
    "qs = [1, 5, 10, 100, 200, 400]\n",
    "\n",
    "# Figure\n",
    "# fig, axs = plt.subplots(1, len(qs), figsize=(3*len(qs), 3))\n",
    "\n",
    "# for i, q in enumerate(qs):\n",
    "#     qperc = q/Nfaces * 100 # Percentage of faces used\n",
    "#     face_rec = ...\n",
    "\n",
    "#     axs[i].imshow(face_rec.reshape(face_images.shape[1:]), cmap='grey')\n",
    "#     axs[i].set_title( str(q) + ' PCs (' + str(qperc) + '%)')\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f681255",
   "metadata": {},
   "source": [
    "#### Canonical basis vs PCs\n",
    "Explain what is the difference between using the canonical basis and the mdoes to express the images, and why we can reduce the dimensionality with POD and not with the canonical basis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e6faf",
   "metadata": {},
   "source": [
    "##### - Canonical basis\n",
    "How does this work? In the canonical basis, the image is the sum of some weights multiplied by the canonical basis:\n",
    "\\begin{equation}\n",
    "    \\mathbf{x} = \\sum_{i=1}^{m} w_i \\mathbf{b}_i\n",
    "\\end{equation}\n",
    "\n",
    "- To do: \n",
    " 1. Define the canonical basis $\\mathbf{B}=[\\mathbf{b}_1, \\cdots \\mathbf{b}_m]$\n",
    " 2. Obtain the weights $w_i$ of the first 4 directions (n_basis=4)  $\\mathbf{W}=[\\mathbf{w}_1, \\cdots \\mathbf{w}_m]$\n",
    " 3. Show how the first 4 basis vectors look like ($b_i$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 10\n",
    "# face_orig = face_X[:, index] # original face\n",
    "\n",
    "# What are the weights?\n",
    "\n",
    "# Canonical basis\n",
    "B = ...\n",
    "# Choose the first 4 directions\n",
    "n_basis = 4\n",
    "\n",
    "# X = BÂ·W\n",
    "W = ... # weigths\n",
    "\n",
    "# # Plotting function\n",
    "# fig, axs = plt.subplots(1, (n_basis+1), figsize=((n_basis+1)*3, 3))\n",
    "# fig.set_facecolor('white')\n",
    "# axs[0].imshow(face_orig.reshape(face_images.shape[1:]), cmap='grey')\n",
    "# axs[0].set_xticks([])\n",
    "# axs[0].set_yticks([])\n",
    "\n",
    "# for i in range(1, n_basis+1):\n",
    "#     axs[i].imshow(..., cmap='Greys')\n",
    "#     axs[i].yaxis.set_label_coords(-0.2,0.5)\n",
    "#     axs[i].set_xticks([])\n",
    "#     axs[i].set_yticks([])\n",
    "#     if i == 1:\n",
    "#         axs[i].set_ylabel('= {:.3f} $\\cdot$'.format(W[i-1]), rotation=0, fontsize=14)\n",
    "#     else:\n",
    "#         axs[i].set_ylabel('+ {:.3f} $\\cdot$'.format(W[i-1]), rotation=0, fontsize=14)\n",
    "\n",
    "# fig.subplots_adjust(left=0, right=1, bottom=0., top=1, wspace=0.4)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f167750",
   "metadata": {},
   "source": [
    "##    4. Plot original face VS reconstruction with 100 modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = 100\n",
    "# index = 10\n",
    "\n",
    "# face_orig = \n",
    "# face_rec = \n",
    "\n",
    "# Plot them side by side (do it yourself this time !)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212c819",
   "metadata": {},
   "source": [
    "#### - POD basis\n",
    "How does this work? In the POD basis, the image is the sum of some weights multiplied by the POD basis:\n",
    "\\begin{equation}\n",
    "    \\mathbf{x} = \\mu(x) + \\sum_{i=1}^{m} a_i \\boldsymbol{\\phi}_i\n",
    "\\end{equation}\n",
    "\n",
    "- To do: \n",
    " 1. POD basis already defined: $\\boldsymbol{\\Phi}=[\\boldsymbol{\\phi}_1, \\cdots \\boldsymbol{\\phi}_m]$\n",
    " 2. POD coefficients already known too: $\\mathbf{A}=[\\mathbf{a}_1, \\cdots \\mathbf{a}_m]$ \n",
    " 3. Show how the first 4 basis vectors look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = ...\n",
    "# face  = ...\n",
    "\n",
    "n_basis = 4 # 4 first directions (over 4096 ...)\n",
    "\n",
    "# What are the weights?\n",
    "\n",
    "a = At[:n_basis, index]\n",
    "\n",
    "# plot of the first 4 basis vectors a_i (copypaste from above and modify what needs to be modified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f484d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLVKI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
