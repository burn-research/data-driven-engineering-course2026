{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a9a49454",
      "metadata": {
        "id": "a9a49454"
      },
      "source": [
        "# Session 3 (a): Toy Datasets\n",
        "\n",
        "First, we perform clustering on a simple dataset to illustrate how clustering works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52cff70d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "52cff70d",
        "outputId": "f9e2201c-4aad-4a8e-f681-a9166310b944"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "n_samples = 500\n",
        "random_state = 170 # fix it for reproducibility!\n",
        "\n",
        "# create dataset\n",
        "dataset = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 1.0, 1.0], random_state=random_state) # Q: What is cluster_std attribute? (always check the documentation!)\n",
        "X = dataset[0] # data\n",
        "y = dataset[1] # labels\n",
        "\n",
        "# visualise dataset\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.show()\n",
        "\n",
        "# # quick check !\n",
        "# print(X.shape)\n",
        "# print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3cf684c",
      "metadata": {
        "id": "c3cf684c"
      },
      "source": [
        "## K-Means\n",
        "\n",
        "K-Means clusters the points based on the Euclidean distance between them $d_{i,j} = ||\\mathbf{x}_i -  \\mathbf{x}_j||^2_2$. The goal is to minimise the distance between points in the same cluster, and maximise the distance between points from different clusters.\n",
        "\n",
        "The objective function is:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\min \\left( \\sum_{i=0}^n ||\\mathbf{x}_i - \\sum_{k=0}^{n_k} \\delta_{i, k} \\boldsymbol{\\mu}_k||^2_2\\right) \\ \\ \\ k = 1, \\dots, n_k\n",
        "\\end{equation}\n",
        "\n",
        "which is also called the inertia, and where $\\delta_{i, k}$ is the cluster assignment associated to the point $x_i$ (0 or 1) and $\\mu_k$ is the centroid of the k-th cluster.\n",
        "\n",
        "The algorithm works iteratively:\n",
        "\n",
        "0) Initialise the $\\mu_k$ centroids\n",
        "1) Define the cluster assignment $\\delta_{i, k}$ for each $x_i$ ($x_i$ is associated with the closest centroid)\n",
        "2) Minimise the objection function\n",
        "3) Update $\\mu_k$ and go back to (1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d775930",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "6d775930",
        "outputId": "595d39b7-7ca5-40a8-c7ec-f340c02b6f8a"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# - center the dataset\n",
        "# - apply KMeans https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans\n",
        "# - plot the data with the centroids and the labels found by KMeans\n",
        "\n",
        "# from ... import ...\n",
        "\n",
        "# 1) Center the dataset:\n",
        "# X0 = ...\n",
        "\n",
        "# 2) Apply kmeans\n",
        "# kmeans = ...\n",
        "\n",
        "# centroids = ...\n",
        "# labels = ...\n",
        "\n",
        "# 3) Plot\n",
        "# plt.scatter(...) # plot the data\n",
        "# plt.scatter(...) # plot the centroids\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d2100d",
      "metadata": {
        "id": "b5d2100d"
      },
      "source": [
        "# Clustering to do Local PCA (LPCA)\n",
        "\n",
        "The goal of the exercise is to do clustering on a dataset representing a noisy 2D non-linear function.\n",
        "* How do we select the correct number of clusters?\n",
        "* Why LPCA works better than PCA on a non-linear dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae6e6c9",
      "metadata": {
        "id": "3ae6e6c9"
      },
      "source": [
        "First thing, we create our synthetic dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c58ab3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "f9c58ab3",
        "outputId": "ed36849d-a8a0-4c66-f258-cc290eb6e0df",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "def non_linear_func_orig(x):\n",
        "    y = np.sin(x) + np.sin(1.5*x)\n",
        "    return y\n",
        "\n",
        "def non_linear_func(x):\n",
        "    y = non_linear_func_orig(x) + 0.25*np.random.randn(x.size)\n",
        "    return y\n",
        "\n",
        "# This code is used to create our synthetic dataset\n",
        "size = 1000\n",
        "seed = 42\n",
        "np.random.seed(seed) # Fix it for reproducibility\n",
        "\n",
        "x = np.random.rand(size) * 2.6*np.pi - np.pi/2\n",
        "y = non_linear_func(x)\n",
        "\n",
        "limits = [np.pi/2.5, 1.2*np.pi]\n",
        "eps = np.pi/10\n",
        "\n",
        "mask = ((x < limits[0] + eps) & (x > limits[0] - eps)) | (x < limits[1] + eps) & (x > limits[1] - eps)\n",
        "x = x[~mask]\n",
        "y = y[~mask]\n",
        "\n",
        "# Create the noisy samples dataset\n",
        "X = np.zeros((x.size, 2))\n",
        "X[:,0] = x\n",
        "X[:,1] = y\n",
        "\n",
        "x_orig = np.linspace(x.min(), x.max(), 200)\n",
        "y_orig = non_linear_func_orig(x_orig)\n",
        "\n",
        "# We can plot the dataset and the original non-linear function\n",
        "plt.scatter(X[:,0], X[:,1], c='b', alpha=0.5) # Noisy samples\n",
        "plt.plot(x_orig, y_orig, c='cyan', lw=5) # Original function\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()\n",
        "\n",
        "# quick check !\n",
        "# print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f427673",
      "metadata": {
        "id": "6f427673"
      },
      "source": [
        "## Global PCA\n",
        "Now we apply the PCA and try to reconstruct the dataset using only one dimension.\n",
        " - To do:\n",
        "    - obtain X0 (dataset centred and scaled with mean and std)\n",
        "    - apply PCA\n",
        "    - recontruct the solution with one dimension (q=1)\n",
        "        - hint:\n",
        "            - X     = Z  @ A.T\n",
        "            - X_rec = Zq @ Aq.T\n",
        "    - plot the reconstruction vs the original dataset\n",
        "\n",
        "\n",
        " - hint: the documentation and examples to use the PCA object are at:\n",
        "       https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bec782f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "8bec782f",
        "outputId": "611de6b7-a125-4150-a2e9-e8d7cd03de9e"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# - Apply PCA\n",
        "# - Reconstruct with a single PC\n",
        "\n",
        "# from ... import ...\n",
        "\n",
        "# 1) Apply PCA\n",
        "# scaler = ... # (or use X_mean and X_std)\n",
        "# X0 = ...\n",
        "\n",
        "# pca = ... # don't forget to fit the pca object from sklearn !\n",
        "\n",
        "# A = ... # loadings\n",
        "# Z = ... # scores\n",
        "\n",
        "# 2) Reconstruct with 1 PC\n",
        "# q = 1\n",
        "# X0_rec = ...\n",
        "# X_rec = ...\n",
        "\n",
        "# Plot the reconstruction VS original\n",
        "# plt.scatter(X[:,0], X[:,1], c='b', alpha=0.5) # Noisy samples\n",
        "# plt.plot(x_orig, y_orig, c='cyan', lw=5) # Original\n",
        "# plt.scatter(X_rec[:,0], X_rec[:,1], c='red', alpha=0.5) # Reconstructed samples\n",
        "# plt.xlabel('x')\n",
        "# plt.ylabel('y')\n",
        "# plt.show()\n",
        "\n",
        "# Q: Discuss the results! Why does it look bad?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "706f512f",
      "metadata": {
        "id": "706f512f"
      },
      "source": [
        "## Clustering\n",
        "\n",
        "We can try and improve the reconstruction accuracy using a local approac ('piecewise'). The first thing to do is then to cluster the dataset using kmeans.\n",
        "- To do:\n",
        "    - Use KMeans object to obtain the cluster labels or indexes (=`idx`) with *init='random'* and *n_init='auto'*\n",
        "    - Use a number of clusters (k) of your choice.\n",
        "    - Plot the dataset and colour it by the value of the label\n",
        "\n",
        "- Hint: the documentation and examples to use the PCA object are at:\n",
        "       https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62e3728",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "b62e3728",
        "outputId": "8e27144b-d1b8-49d6-8bbf-1b3b59c963ce"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# - Apply KMeans to the dataset\n",
        "\n",
        "# from ... import ...\n",
        "\n",
        "# 1) Choose the number of clusters\n",
        "# k = ...\n",
        "\n",
        "# 2) Apply kmeans to the centred dataset (see above)\n",
        "# kmeans = ...\n",
        "\n",
        "# centroids = ...\n",
        "# labels = ...\n",
        "\n",
        "# 3) Plot\n",
        "# plt.scatter(...) # plot the data\n",
        "# plt.scatter(...) # plot the centroids\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38b55eb",
      "metadata": {
        "id": "b38b55eb"
      },
      "source": [
        "## Selection of the clusters' number\n",
        "\n",
        "In this case we can visually identify the number of clusters, because we have only two dimensions. In higher dimensions, it is not possible to visualise the dataset. Also, we would prefer to have an automatic method to select the correct number of clusters.\n",
        "\n",
        "We can use the Davies-Boulding score to estimate the number of clusters (https://scikit-learn.org/stable/modules/clustering.html#davies-bouldin-index)\n",
        "\n",
        "- To do:\n",
        "    - Calculate the DB score for a range of k (number of clusters) that goes from 2 to 10.\n",
        "    - Plot the DB score as a function of k.\n",
        "    - Select n_clusters based on the DB score\n",
        "   \n",
        "   \n",
        "- Hint:\n",
        "    - the documentation and examples to use the PCA object are at:\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html\n",
        "    - you can use a 'for' loop to calculate the DB for different k\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3155a211",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "3155a211",
        "outputId": "27d10db8-b754-4255-cdfb-1e5ae7769305"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# Compute and plot the DB index for n_cluster = 2 to 10\n",
        "\n",
        "# from ... import ...\n",
        "\n",
        "# 1) Create the range of k and the corresponding DB score\n",
        "# k_array = ...\n",
        "# db_score_array = ...\n",
        "\n",
        "# 2) Plot DB score vs n_clusters\n",
        "# plt.plot(k_array, db_score_array)\n",
        "# plt.xlabel('k')\n",
        "# plt.ylabel('db_score')\n",
        "# plt.show()\n",
        "\n",
        "# 3) Select n_clusters based on db_scores\n",
        "# index = ...\n",
        "# n_clusters = ...\n",
        "# print(f'n_clusters = {n_clusters}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0c016f3",
      "metadata": {
        "id": "b0c016f3"
      },
      "source": [
        "## Local PCA\n",
        "\n",
        "Now we can now apply the PCA inside each cluster.\n",
        "- To do:\n",
        "    - apply PCA for each cluster\n",
        "    - plot the reconstruction using only the first PC.\n",
        "- Hint:\n",
        "    - Use a 'for' loop to apply the PCA in each cluster.\n",
        "    - to select only the data of a single cluster use a mask:\n",
        "           To select the data with label 0:\n",
        "             mask = (idx == 0)\n",
        "             X_k = X[mask]\n",
        "    - To get the correct reconstruction, you need to **center and scale** the data **in each cluster** before applying the PCA, and then de-center and de-scale the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b996cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "e1b996cc",
        "outputId": "766bee08-218c-47b3-ec62-a96616e4bbb6"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# - Apply PCA to each cluster\n",
        "\n",
        "# 1) Compute KMeans with the correct number of clusters\n",
        "# kmeans = ...\n",
        "\n",
        "# centroids = ...\n",
        "# labels = ...\n",
        "\n",
        "# 2) Apply PCA for each cluster\n",
        "\n",
        "# q = 1\n",
        "\n",
        "# Create the PCA object\n",
        "# pca = PCA()\n",
        "\n",
        "# Loop on clusters\n",
        "# for k in range(n_clusters):\n",
        "#     print(f'k = {k}')\n",
        "\n",
        "#     # Select the points belonging to cluster k using the labels\n",
        "#     mask = ... # Create the mask\n",
        "#     X_k = X[mask]\n",
        "\n",
        "#     # Scale the subdataset\n",
        "#     ...\n",
        "#     X0_k = ...\n",
        "\n",
        "#     # Perform the PCA on this scaled subdataset\n",
        "#     ...\n",
        "#     A_k = ... # loadings\n",
        "#     Z_k = ... # scores\n",
        "\n",
        "#     # Reconstruct, uncenter and unscale\n",
        "#     X0_k_rec = ...\n",
        "#     X_k_rec : ...\n",
        "\n",
        "#     # Plot the reconstruction\n",
        "#     plt.scatter(...) # Noisy samples\n",
        "#     plt.scatter(...) # Reconstructed samples\n",
        "\n",
        "# Plot the original\n",
        "# plt.plot(x_orig, y_orig, c='cyan', lw=5, alpha=0.7)\n",
        "# plt.show()\n",
        "\n",
        "# Q: Discuss the results! Why does it still look bad?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc4b887",
      "metadata": {
        "id": "1dc4b887"
      },
      "source": [
        "## Local PCA with VQPCA\n",
        "\n",
        "We can compare the KMEANS results with VQPCA. To perform VQPCA, we need the [OpenMORe](https://github.com/burn-research/OpenMORe) library. You can run the next cell to install it.\n",
        "VQPCA is a clustering algorithm that assign points to the clusters based on the reconstruction error, so it tries to find clusters that can be well represented by a linear manifold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c162f0c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c162f0c7",
        "outputId": "885759c7-68a4-443e-922f-f6d261089426"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/burn-research/OpenMORe.git\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0,'/content/OpenMORe')\n",
        "\n",
        "import OpenMORe.clustering as clustering\n",
        "# import OpenMORe.clustering as clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60e30738",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60e30738",
        "outputId": "077f7dc8-4921-4386-fb45-76537c7c43ca"
      },
      "outputs": [],
      "source": [
        "# This is a dictionary used to set the VQPCA parameters.\n",
        "settings_clustering = {\n",
        "    #centering and scaling options\n",
        "    \"center\"                    : True,\n",
        "    \"centering_method\"          : \"mean\",\n",
        "    \"scale\"                     : True,\n",
        "    \"scaling_method\"            : \"auto\",\n",
        "\n",
        "    #set the initialization method (random, observations, kmeans, pkcia, uniform)\n",
        "    \"initialization_method\"     : \"uniform\",\n",
        "\n",
        "    #set the number of clusters and PCs in each cluster\n",
        "    \"number_of_clusters\"        : 3,\n",
        "    \"number_of_eigenvectors\"    : 1,\n",
        "\n",
        "    #enable additional options:\n",
        "    \"correction_factor\"         : \"off\",    # --> enable eventual corrective coefficients for the LPCA algorithm:\n",
        "                                            #     'off', 'c_range', 'uncorrelation', 'local_variance', 'phc_multi', 'local_skewness' are available\n",
        "\n",
        "    \"classify\"                  : False,    # --> call the method to classify a new matrix Y on the basis of the lpca clustering\n",
        "    \"write_on_txt\"              : False,    # --> write the idx vector containing the label for each observation\n",
        "    \"evaluate_clustering\"       : True,     # --> enable the calculation of indeces to evaluate the goodness of the clustering\n",
        "    \"neighbors_number\"          : 0,\n",
        "\n",
        "    \"kNN_post\"                  : False,     # activate the kNN algorithm once the convergence is achieved\n",
        "}\n",
        "\n",
        "# To do: follow the example in\n",
        "# https://github.com/burn-research/OpenMORe/blob/master/examples/clustering/lpcaExample.py\n",
        "# to find the vqpca labels, then plot the clusters\n",
        "\n",
        "# First we create the model and then we fit it to the dataset\n",
        "model = clustering.lpca(X, settings_clustering)\n",
        "idx_vqpca = model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4e7806c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we can plot the clusters\n",
        "plt.scatter(X[:,0], X[:,1], c=idx_vqpca)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gmHAkchMc8QA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "gmHAkchMc8QA",
        "outputId": "61693168-419f-4404-bbe1-cf1eaa5f926f"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# - Apply PCA to each cluster\n",
        "\n",
        "# q = 1\n",
        "\n",
        "# Create the PCA object\n",
        "# pca = PCA()\n",
        "\n",
        "# Loop on clusters\n",
        "# for k in range(n_clusters):\n",
        "#     print(f'k = {k}')\n",
        "\n",
        "#     # Select the points belonging to cluster k using the labels\n",
        "#     mask = ... # Create the mask\n",
        "#     X_k = X[mask]\n",
        "\n",
        "#     # Scale the subdataset\n",
        "#     ...\n",
        "#     X0_k = ...\n",
        "\n",
        "#     # Perform the PCA on this scaled subdataset\n",
        "#     ...\n",
        "#     A_k = ... # loadings\n",
        "#     Z_k = ... # scores\n",
        "\n",
        "#     # Reconstruct, uncenter and unscale\n",
        "#     X0_k_rec = ...\n",
        "#     X_k_rec : ...\n",
        "\n",
        "#     # Plot the reconstruction\n",
        "#     plt.scatter(...) # Noisy samples\n",
        "#     plt.scatter(...) # Reconstructed samples\n",
        "\n",
        "# Plot the original\n",
        "# plt.plot(x_orig, y_orig, c='cyan', lw=5, alpha=0.7)\n",
        "# plt.show()\n",
        "\n",
        "# Q: Discuss the results! Why does it still look bad?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac870b04",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MLVKI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
